The paper: How Well Apply Multimodal Mixup and Simple MLPs Backbone to Medical Visual Question Answering? has been accepted by the BIBM conference. If you want to use the code, please cite this paper.

The python environment used is python3.8, pytorch and pytorch-lightning are used, please configure manually.

Second, you also need to download the SLAKE and VQA-RAD datasets and put them in ./data/ref.

SLAKE datasets download: https://www.med-vqa.com/slake/#gt-Download

